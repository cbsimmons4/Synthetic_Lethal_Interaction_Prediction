\section{Background and Related Work} % {{{
\label{sec:background}

\subsection{Machine Learning on Graphs and Node2Vec} % {{{
\label{sec:node2vec}

Node2Vec is one of the prominent applications used to support the findings in this study. In the field of machine learning, often a set of features is known prior to solving a problem; however, Node2Vec's purpose is to provide an algorithmic framework for learning continuous feature representations for neural network nodes when the features are not so obvious. Node2Vec aims to add flexibility in exploring neighborhoods of nodes, or nodes that are grouped closely together. The program itself aids in multi-label classification (attaching multiple valid labels to an input) and link prediction (estimating which nodes are likely to have edges connecting them).

In terms of genomics, multi-label classification comes into play when attaching likelihood of a gene being synthetic lethal or not. Likewise, link prediction comes into play to gauge whether any two genes have interactions with one another. Thus, one can see how useful this algorithm to learn features is with respect to studying cancerous patients; given data about those afflicted with cancer, Node2Vec learns which features of the data given are the most likely to be related to the cancer as well as which features are intertwined.

Node2Vec's algorithm is semi-supervised. Humans at first decide which features to throw into the algorithm, but Node2Vec ultimately weights these features and determines which are worthwhile. Its goal was to be more flexible and scalable than the previous feature learning algorithms that existed. To do this, Node2Vec incorporated parameters the programmer can tune upon execution, particularly the random walk size and the search bias. The walk size determines the extent to which the algorithm explores nodes from a given source, and the search bias is the likelihood with which Node2Vec returns to nodes it has already explored. Tweaking these parameters can give vastly different depictions of the features learned by the network. As such, they are useful for exploring any data presented from a variety of angles.

Fine-tuning the neural network occurs in a sequence of three steps: preprocessing and computing of transition probabilities, random walk simulations, and finally optimization using stochastic gradient descent. The preprocessing involves a variety of calculations which determine the likelihoods to which given nodes are related prior to any walk. Then the random walk simulations effectively traverse the network's pathways in an effort to explore relatedness of nodes in a framework consistent with the walk size and search bias parameters. Finally, stochastic gradient descent iteratively calculates the partial derivative of the cost function with respect to the input vectors and adjusts the weights in the network accordingly (the learning aspect).

Node2Vec, because of the freedom to tune the walk size and search bias, can depict novel relationships between nodes. For example, having a large walk size with a low search bias (low likelihood to return to previous nodes) will likelier depict a network in which nodes are connected for long distances but are not grouped as much in neighborhoods. Decreasing the walk size and increasing the search bias depicts a scenario where nodes are not connected by edges for long pathways but neighborhoods of nodes are emphasized. Clearly, this flexibility is useful as it pertains to machine learning in cancer research; researchers can apply hypotheses to the algorithm in novel ways and based on what they predict, fine-tuning of the parameters could give new insights.

Ultimately, Node2Vec is useful mainly for its scalability and flexibility especially with respect to feature learning in bioinformatics. Node2Vec was employed in order to analyze the extent to which genetic interactions occurred in the two yeast species. Because of the scalability, there were no issues analyzing the amount of data present; because of the flexibility, it was possible to analyze link prediction for genetic interactions within the two species as well as the homologs of interactions between the two species.



\subsection{Genetic Interactions In Yeast and synthetic lethality regarding cancer} % {{{
\label{sec:genetic_interactions}
Genetic interactions is a measure of the effect of a modification in one gene on another gene. For our research, we are particularly interested in synthetic lethal interactions. Synthetic lethality involves multiple genes, where the loss of either gene alone has very little impact on the cell, but the loss of all the genes in the interaction leads to a massive decrease in fitness or even cell death (Madhukar, Elemento, \& Pandev, 2015). SL interactions are difficult to measure in humans, thus our interest in predicting these interactions. These interactions have very important significance in the world of biology and medicine, for predicting them can provide therapeutically exploitable weaknesses in tumors. All genetic interactions can be very broadly classified as positive or negative, explaining whether the interaction increased or decreased the geneâ€™s fitness (Jasnos and Korona, 2007). The interactions are crucial in describing functional relationships among genes and their corresponding proteins, as well as explaining complex biological processes and diseases. Synthetic lethality is one of the most significant and researched gene interaction, because it is the extreme case of a negative interaction.

Synthetic lethality can be used to selectively target cancer cells. Predicting SLs have been successful in pharmacological PARP inhibition in BRCA-mutated tumors (Weil and Chen, 2011). However, predicting these synthetic lethal interactions can go far beyond that. Many somatic mutations in cancer genes cannot be targeted directly, however, some may be actionable through the identified synthetic lethal interactions (Emerling et al., 2013). Standard chemotherapy approaches for cancer were previously discovered on the basis of their ability to kill cells which divide rapidly. The toxicity to these dividing cells are a cause for the side effects of chemotherapy, such as hair loss, nausea, and immunosuppression (Chan and Giaccia, 2013). In hopes of reducing these side effects, cancer research in the past has been largely focused on identifying traits which are tumor-specific and may be exploited for selective targeting. 

The DNA mutation rate is very low in normal cells, but there are many somatic mutations in cancer cells. A drug that targets the synthetic lethal partner gene of a cancer-specific mutated gene will kill the cancer cells, whilst sparing the normal cells. Originally, SL was discovered in genetic experiments of yeast and fruit fly. It was proposed by Hartwell et al as a new framework for anticancer therapies in 1997, and has been intensely researched since. More recently, an SL-based drug, specifically the inhibitor of poly ADP-ribose polymerases (PARPs), which has synthetic lethal interactions with the BRCA1 and BRCA2, two well-known genes whose mutations lead to breast cancer, has achieved clinical success for breast cancer therapy. The main approach to discovering SL is screening using RNA interference. However, SL screening has limitations due to high cost, false-positives, lack of mechanistic interpretation, and inconsistency among cell lines (Conde-Pueyo \& Munteanu, 2009). Thus, very few SL pairs have been discovered in human cancer. Yeast is an extremely popular model organism for human research due to the abundant data of genetic interactions, including synthetic lethal. 

Yeast is one of the simplest eukaryotic organisms. It is an extremely important organism for biological research because many essential cellular processes are the same in yeast and humans. By studying yeast, researchers gain more of an understanding on basic molecular processes in humans. However, even for yeast, only a small portion of gene pairs have been covered using synthetic lethal screening. For this reason, relying on computational methods is extremely important for large-scale discovery of synthetic lethal interactions. In the past decade, several machine learning method have been proposed and tested on the benchmark datasets of yeast, which revealing that computational methods do have great potential in analyzing and predicting SL (Qi, Suhail, Lin, Boeke, \& Bader, 2008). Qi et al applied diffusion kernels defined on the network of yeast SL interactions in a support vector machine classifier for the prediction of novel genetic interactions and protein co-complex membership. Palagudu et al extracted many features from protein-protein interaction entwords, which were used in an SVM to predict new synthetic lethal interactions. Both of these methods tend to focus on a particular type of features and use a single machine learning method. However, as SL interactions are highly complex, they are likely to be caused by different mechanisms. Thus, our goal was to provide a more integrative analysis of multiple features.


\subsection{Intelligent Merging of Species} % {{{
Organisms are constantly interacting with other species through physical contact, leading to changes on a molecular level. The goal of intelligently merging species is to combine multiple heterogeneous networks with different connectivity patterns, to achieve more accurate inferences. However, there are many challenges when it comes to transferring knowledge between species. Mainly, different species have different genetic architectures. However, because of the availability of complete genomic sequence of humans and other species, the opportunity for understanding gene functions is tremendous. Gene function can be inferred in multiple ways, including DNA microarray expression data. Microarrays now allow biologists to formulate models of gene expression on a larger scale than anything that has been seen several years ago. 

Initially, analysis of this data focused on clustering algorithms and self-organizing maps, which attempt to automatically locate clusters of genes with similar expression patterns, thus they may share similarity in function. However, recently, methods have been created to apply a collection of learning techniques to a set of microarray expression data from yeast using kernel methods. Merging species will lead to improved performance, due to the kernelâ€™s ability to incorporate prior knowledge about the heterogeneity of the data. Prior knowledge of heterogeneity should be exploited when choosing subsets of input features for use in classification (Pavlidis, Weston, Cai, Grundy, 2001). Feature selection is extremely important to intelligently merging species. 

There have been computational approaches to transfer knowledge between species, which have mainly relied on measures of heredity, ie. genetic homology (Fan, Cannistra, Fried, Lim, Shaffner, Crovella, Hescott, \& Leiserson, 2018). However, only a small subset of genes do have homologs, which limits the amount of transferable knowledge. Genes also repurpose and change functions, further complicating this transfer of knowledge. 

Fan et al has taken a different approach to transferring knowledge across species by using explicit measures of functional similarity of proteins between species to expand on the notion of homology. Using a kernel-based method, Homology Assessment across Networks using Diffusion and Landmarks, has allowed for the ability to integrate sequences and network structures to create embedding where proteins from different species are included in the same vector space. HANDL-embedding can co-locate gene pairs with synthetic lethal interactions in HANDL-space both within and across species. HANDL provides homology scores for gene pairs in different species with are associated with pairwise gene function. Fan et al used HANDL to identify synthetic lethal interactions between S. cerevisiae (S.c.) and S. pombe (S.p.), which are two different species of yeast. HANDL allows for the training of classifiers for multiple species, rather than usual SL prediction methods which do not account for multiple species. 

Mashup is a framework designed for scalable and robust network integration where diffusion in each network is first analyzed to characterize the topological context of nodes. Then, the topological patterns in each individual network are shown using low-dimensional vectors, one per gene or protein. Using these vectors, one can use machine learning to derive functional insights about genes, specifically, genetic interaction (Cho, Berger \& Peng, 2016). 

Although different approaches have been taken to intelligently merge species, we used the data from HANDL on S. cerevisiae and S. pombe to determine a better way of predicting synthetic lethal interactions. Intelligently merging species has many different uses, however, for the purpose of this research topic, we focused on intelligently merging species to predict synthetic lethal interactions between genes. 

